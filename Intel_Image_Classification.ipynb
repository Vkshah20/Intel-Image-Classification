{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Intel Image Classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vkshah20/Intel-Image-Classification/blob/master/Intel_Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-Ztk1B5k9I0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import  Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import  Callback, TensorBoard\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHyM6DITlNmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyCall(Callback):\n",
        "    def on_epoch_end(self,model, logs={}):\n",
        "        if(logs['acc'] > 0.95):\n",
        "            self.model.stop_training = True\n",
        "\n",
        "calls = MyCall()\n",
        "tbCall = TensorBoard('log', histogram_freq = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdcHoO9koQCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "# Create a ZipFile Object and load sample.zip in it\n",
        "with ZipFile('drive/My Drive/DATA.zip', 'r') as zipObj:\n",
        "    zipObj.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D7C68M2lV8G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "59d1ee7a-cb1a-4e86-cbd6-935fe93b8663"
      },
      "source": [
        "trainP = 'DATA/seg_train'\n",
        "testP = 'DATA/seg_test'\n",
        "\n",
        "trainDataGen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range=40,\n",
        "    zoom_range=0.2,)\n",
        "testDataGen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "trainGen = trainDataGen.flow_from_directory(\n",
        "    trainP,\n",
        "    target_size = (150,150),\n",
        "    batch_size = 64,\n",
        "    class_mode = 'categorical')\n",
        "\n",
        "testGen = testDataGen.flow_from_directory(\n",
        "    testP,\n",
        "    target_size = (150,150),\n",
        "    batch_size = 64,\n",
        "    class_mode = 'categorical')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14034 images belonging to 6 classes.\n",
            "Found 3000 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gavVmGenlnMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), input_shape = (150,150, 3), activation = 'relu'),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Conv2D(64, (3,3), activation = 'relu'),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Conv2D(128, (3,3), activation = 'relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(128, (3,3), activation = 'relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(1024, activation = 'relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation = 'relu'),\n",
        "    Dense(6, activation = 'softmax'),\n",
        "    ])\n",
        "model.compile('adam', 'categorical_crossentropy', ['acc'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FoY7p9-WA7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "9c1e3d05-eb9e-4d69-fe8b-afaedbbe3c98"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "!zip -r log.zip log\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: log/ (stored 0%)\n",
            "  adding: log/train/ (stored 0%)\n",
            "  adding: log/train/events.out.tfevents.1592206628.bc0914672ea0.119.269.v2 (deflated 84%)\n",
            "  adding: log/train/plugins/ (stored 0%)\n",
            "  adding: log/train/plugins/profile/ (stored 0%)\n",
            "  adding: log/train/plugins/profile/2020_06_15_07_37_15/ (stored 0%)\n",
            "  adding: log/train/plugins/profile/2020_06_15_07_37_15/bc0914672ea0.trace.json.gz (deflated 0%)\n",
            "  adding: log/train/plugins/profile/2020_06_15_07_37_15/bc0914672ea0.tensorflow_stats.pb (deflated 72%)\n",
            "  adding: log/train/plugins/profile/2020_06_15_07_37_15/bc0914672ea0.overview_page.pb (deflated 59%)\n",
            "  adding: log/train/plugins/profile/2020_06_15_07_37_15/bc0914672ea0.kernel_stats.pb (deflated 92%)\n",
            "  adding: log/train/plugins/profile/2020_06_15_07_37_15/bc0914672ea0.input_pipeline.pb (deflated 58%)\n",
            "  adding: log/train/events.out.tfevents.1592206635.bc0914672ea0.profile-empty (deflated 5%)\n",
            "  adding: log/validation/ (stored 0%)\n",
            "  adding: log/validation/events.out.tfevents.1592206734.bc0914672ea0.119.2775.v2 (deflated 65%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9cDjpY14Ig5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86a5434a-0455-4d8a-c7ca-ce15e53a52bd"
      },
      "source": [
        "model.fit_generator(\n",
        "    trainGen,\n",
        "    epochs = 1000,\n",
        "    callbacks = [calls, tbCall],\n",
        "    validation_data = testGen,)\n",
        "model.save('kaggle.hdf5')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-d7331a270cf2>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/1000\n",
            "220/220 [==============================] - 100s 452ms/step - loss: 1.1676 - acc: 0.5316 - val_loss: 0.9000 - val_acc: 0.6320\n",
            "Epoch 2/1000\n",
            "220/220 [==============================] - 99s 449ms/step - loss: 0.9052 - acc: 0.6611 - val_loss: 0.7704 - val_acc: 0.7193\n",
            "Epoch 3/1000\n",
            "220/220 [==============================] - 98s 448ms/step - loss: 0.7780 - acc: 0.7144 - val_loss: 0.7530 - val_acc: 0.7293\n",
            "Epoch 4/1000\n",
            "220/220 [==============================] - 98s 444ms/step - loss: 0.7242 - acc: 0.7349 - val_loss: 0.6155 - val_acc: 0.7830\n",
            "Epoch 5/1000\n",
            "220/220 [==============================] - 97s 441ms/step - loss: 0.6632 - acc: 0.7545 - val_loss: 0.6668 - val_acc: 0.7677\n",
            "Epoch 6/1000\n",
            "220/220 [==============================] - 97s 442ms/step - loss: 0.6166 - acc: 0.7772 - val_loss: 0.5003 - val_acc: 0.8203\n",
            "Epoch 7/1000\n",
            "220/220 [==============================] - 97s 439ms/step - loss: 0.5802 - acc: 0.7907 - val_loss: 0.5086 - val_acc: 0.8203\n",
            "Epoch 8/1000\n",
            "220/220 [==============================] - 97s 440ms/step - loss: 0.5498 - acc: 0.8040 - val_loss: 0.5418 - val_acc: 0.8080\n",
            "Epoch 9/1000\n",
            "220/220 [==============================] - 95s 433ms/step - loss: 0.5291 - acc: 0.8139 - val_loss: 0.5734 - val_acc: 0.7953\n",
            "Epoch 10/1000\n",
            "220/220 [==============================] - 97s 442ms/step - loss: 0.5081 - acc: 0.8229 - val_loss: 0.5040 - val_acc: 0.8203\n",
            "Epoch 11/1000\n",
            "220/220 [==============================] - 98s 443ms/step - loss: 0.4920 - acc: 0.8245 - val_loss: 0.4503 - val_acc: 0.8430\n",
            "Epoch 12/1000\n",
            "220/220 [==============================] - 97s 440ms/step - loss: 0.4724 - acc: 0.8292 - val_loss: 0.4785 - val_acc: 0.8390\n",
            "Epoch 13/1000\n",
            "220/220 [==============================] - 97s 443ms/step - loss: 0.4539 - acc: 0.8363 - val_loss: 0.5524 - val_acc: 0.8070\n",
            "Epoch 14/1000\n",
            "220/220 [==============================] - 97s 443ms/step - loss: 0.4379 - acc: 0.8453 - val_loss: 0.5513 - val_acc: 0.8087\n",
            "Epoch 15/1000\n",
            "220/220 [==============================] - 97s 442ms/step - loss: 0.4190 - acc: 0.8506 - val_loss: 0.5790 - val_acc: 0.8030\n",
            "Epoch 16/1000\n",
            "220/220 [==============================] - 96s 437ms/step - loss: 0.4092 - acc: 0.8510 - val_loss: 0.5047 - val_acc: 0.8290\n",
            "Epoch 17/1000\n",
            "220/220 [==============================] - 95s 433ms/step - loss: 0.3913 - acc: 0.8568 - val_loss: 0.5839 - val_acc: 0.8163\n",
            "Epoch 18/1000\n",
            "220/220 [==============================] - 96s 436ms/step - loss: 0.3907 - acc: 0.8601 - val_loss: 0.5045 - val_acc: 0.8290\n",
            "Epoch 19/1000\n",
            "220/220 [==============================] - 95s 434ms/step - loss: 0.3788 - acc: 0.8670 - val_loss: 0.4536 - val_acc: 0.8510\n",
            "Epoch 20/1000\n",
            "220/220 [==============================] - 98s 445ms/step - loss: 0.3666 - acc: 0.8650 - val_loss: 0.4299 - val_acc: 0.8527\n",
            "Epoch 21/1000\n",
            "220/220 [==============================] - 98s 447ms/step - loss: 0.3598 - acc: 0.8697 - val_loss: 0.4917 - val_acc: 0.8353\n",
            "Epoch 22/1000\n",
            "220/220 [==============================] - 99s 450ms/step - loss: 0.3465 - acc: 0.8757 - val_loss: 0.4684 - val_acc: 0.8460\n",
            "Epoch 23/1000\n",
            "220/220 [==============================] - 98s 443ms/step - loss: 0.3465 - acc: 0.8722 - val_loss: 0.4795 - val_acc: 0.8427\n",
            "Epoch 24/1000\n",
            "220/220 [==============================] - 97s 440ms/step - loss: 0.3231 - acc: 0.8858 - val_loss: 0.4872 - val_acc: 0.8527\n",
            "Epoch 25/1000\n",
            "220/220 [==============================] - 97s 442ms/step - loss: 0.3227 - acc: 0.8833 - val_loss: 0.4152 - val_acc: 0.8577\n",
            "Epoch 26/1000\n",
            "220/220 [==============================] - 96s 437ms/step - loss: 0.3158 - acc: 0.8844 - val_loss: 0.4561 - val_acc: 0.8493\n",
            "Epoch 27/1000\n",
            "220/220 [==============================] - 96s 438ms/step - loss: 0.3061 - acc: 0.8898 - val_loss: 0.5526 - val_acc: 0.8250\n",
            "Epoch 28/1000\n",
            "220/220 [==============================] - 97s 442ms/step - loss: 0.3009 - acc: 0.8939 - val_loss: 0.4780 - val_acc: 0.8437\n",
            "Epoch 29/1000\n",
            "220/220 [==============================] - 98s 445ms/step - loss: 0.2847 - acc: 0.8952 - val_loss: 0.5133 - val_acc: 0.8407\n",
            "Epoch 30/1000\n",
            "220/220 [==============================] - 98s 444ms/step - loss: 0.2862 - acc: 0.8978 - val_loss: 0.4620 - val_acc: 0.8533\n",
            "Epoch 31/1000\n",
            "220/220 [==============================] - 98s 446ms/step - loss: 0.2714 - acc: 0.9005 - val_loss: 0.4603 - val_acc: 0.8560\n",
            "Epoch 32/1000\n",
            "220/220 [==============================] - 97s 443ms/step - loss: 0.2708 - acc: 0.9038 - val_loss: 0.5208 - val_acc: 0.8510\n",
            "Epoch 33/1000\n",
            "220/220 [==============================] - 99s 448ms/step - loss: 0.2794 - acc: 0.8998 - val_loss: 0.4838 - val_acc: 0.8543\n",
            "Epoch 34/1000\n",
            "220/220 [==============================] - 98s 445ms/step - loss: 0.2672 - acc: 0.9015 - val_loss: 0.4913 - val_acc: 0.8577\n",
            "Epoch 35/1000\n",
            "220/220 [==============================] - 98s 443ms/step - loss: 0.2496 - acc: 0.9114 - val_loss: 0.4662 - val_acc: 0.8553\n",
            "Epoch 36/1000\n",
            "220/220 [==============================] - 97s 440ms/step - loss: 0.2539 - acc: 0.9081 - val_loss: 0.5602 - val_acc: 0.8423\n",
            "Epoch 37/1000\n",
            "220/220 [==============================] - 97s 442ms/step - loss: 0.2387 - acc: 0.9134 - val_loss: 0.5575 - val_acc: 0.8397\n",
            "Epoch 38/1000\n",
            "220/220 [==============================] - 98s 445ms/step - loss: 0.2333 - acc: 0.9158 - val_loss: 0.5519 - val_acc: 0.8383\n",
            "Epoch 39/1000\n",
            "220/220 [==============================] - 98s 444ms/step - loss: 0.2399 - acc: 0.9117 - val_loss: 0.6077 - val_acc: 0.8293\n",
            "Epoch 40/1000\n",
            "220/220 [==============================] - 98s 444ms/step - loss: 0.2271 - acc: 0.9181 - val_loss: 0.5130 - val_acc: 0.8533\n",
            "Epoch 41/1000\n",
            "220/220 [==============================] - 99s 448ms/step - loss: 0.2160 - acc: 0.9216 - val_loss: 0.5286 - val_acc: 0.8533\n",
            "Epoch 42/1000\n",
            "220/220 [==============================] - 98s 447ms/step - loss: 0.2187 - acc: 0.9229 - val_loss: 0.5315 - val_acc: 0.8530\n",
            "Epoch 43/1000\n",
            "220/220 [==============================] - 98s 447ms/step - loss: 0.2118 - acc: 0.9224 - val_loss: 0.5472 - val_acc: 0.8497\n",
            "Epoch 44/1000\n",
            "220/220 [==============================] - 98s 447ms/step - loss: 0.2142 - acc: 0.9218 - val_loss: 0.5688 - val_acc: 0.8400\n",
            "Epoch 45/1000\n",
            "220/220 [==============================] - 98s 447ms/step - loss: 0.1912 - acc: 0.9286 - val_loss: 0.5614 - val_acc: 0.8510\n",
            "Epoch 46/1000\n",
            "220/220 [==============================] - 98s 448ms/step - loss: 0.1990 - acc: 0.9277 - val_loss: 0.5597 - val_acc: 0.8427\n",
            "Epoch 47/1000\n",
            "220/220 [==============================] - 98s 447ms/step - loss: 0.2103 - acc: 0.9249 - val_loss: 0.5457 - val_acc: 0.8517\n",
            "Epoch 48/1000\n",
            "220/220 [==============================] - 99s 450ms/step - loss: 0.1982 - acc: 0.9274 - val_loss: 0.5320 - val_acc: 0.8533\n",
            "Epoch 49/1000\n",
            "220/220 [==============================] - 99s 449ms/step - loss: 0.1948 - acc: 0.9283 - val_loss: 0.5455 - val_acc: 0.8447\n",
            "Epoch 50/1000\n",
            "220/220 [==============================] - 99s 448ms/step - loss: 0.1748 - acc: 0.9365 - val_loss: 0.6491 - val_acc: 0.8423\n",
            "Epoch 51/1000\n",
            "220/220 [==============================] - 99s 448ms/step - loss: 0.1968 - acc: 0.9285 - val_loss: 0.5710 - val_acc: 0.8580\n",
            "Epoch 52/1000\n",
            "220/220 [==============================] - 98s 447ms/step - loss: 0.1922 - acc: 0.9311 - val_loss: 0.5951 - val_acc: 0.8373\n",
            "Epoch 53/1000\n",
            "220/220 [==============================] - 98s 446ms/step - loss: 0.1941 - acc: 0.9347 - val_loss: 0.5899 - val_acc: 0.8407\n",
            "Epoch 54/1000\n",
            "220/220 [==============================] - 98s 445ms/step - loss: 0.1874 - acc: 0.9333 - val_loss: 0.5447 - val_acc: 0.8533\n",
            "Epoch 55/1000\n",
            "220/220 [==============================] - 98s 447ms/step - loss: 0.1715 - acc: 0.9389 - val_loss: 0.6017 - val_acc: 0.8407\n",
            "Epoch 56/1000\n",
            "220/220 [==============================] - 98s 446ms/step - loss: 0.1753 - acc: 0.9390 - val_loss: 0.5834 - val_acc: 0.8553\n",
            "Epoch 57/1000\n",
            "220/220 [==============================] - 98s 447ms/step - loss: 0.1722 - acc: 0.9398 - val_loss: 0.5915 - val_acc: 0.8423\n",
            "Epoch 58/1000\n",
            "220/220 [==============================] - 98s 446ms/step - loss: 0.1639 - acc: 0.9398 - val_loss: 0.5417 - val_acc: 0.8623\n",
            "Epoch 59/1000\n",
            "220/220 [==============================] - 98s 445ms/step - loss: 0.1671 - acc: 0.9409 - val_loss: 0.5864 - val_acc: 0.8380\n",
            "Epoch 60/1000\n",
            "220/220 [==============================] - 98s 444ms/step - loss: 0.1687 - acc: 0.9401 - val_loss: 0.5822 - val_acc: 0.8523\n",
            "Epoch 61/1000\n",
            "220/220 [==============================] - 97s 440ms/step - loss: 0.1605 - acc: 0.9428 - val_loss: 0.5570 - val_acc: 0.8687\n",
            "Epoch 62/1000\n",
            "220/220 [==============================] - 97s 439ms/step - loss: 0.1527 - acc: 0.9461 - val_loss: 0.6114 - val_acc: 0.8477\n",
            "Epoch 63/1000\n",
            "220/220 [==============================] - 97s 440ms/step - loss: 0.1568 - acc: 0.9437 - val_loss: 0.5842 - val_acc: 0.8507\n",
            "Epoch 64/1000\n",
            "220/220 [==============================] - 96s 437ms/step - loss: 0.1558 - acc: 0.9441 - val_loss: 0.6133 - val_acc: 0.8607\n",
            "Epoch 65/1000\n",
            "220/220 [==============================] - 98s 444ms/step - loss: 0.1617 - acc: 0.9421 - val_loss: 0.5756 - val_acc: 0.8567\n",
            "Epoch 66/1000\n",
            "220/220 [==============================] - 98s 446ms/step - loss: 0.1467 - acc: 0.9471 - val_loss: 0.6417 - val_acc: 0.8547\n",
            "Epoch 67/1000\n",
            "220/220 [==============================] - 98s 445ms/step - loss: 0.1541 - acc: 0.9451 - val_loss: 0.6086 - val_acc: 0.8560\n",
            "Epoch 68/1000\n",
            "220/220 [==============================] - 98s 447ms/step - loss: 0.1615 - acc: 0.9421 - val_loss: 0.6846 - val_acc: 0.8387\n",
            "Epoch 69/1000\n",
            "220/220 [==============================] - 98s 447ms/step - loss: 0.1583 - acc: 0.9439 - val_loss: 0.5755 - val_acc: 0.8433\n",
            "Epoch 70/1000\n",
            "220/220 [==============================] - 98s 444ms/step - loss: 0.1425 - acc: 0.9485 - val_loss: 0.6584 - val_acc: 0.8483\n",
            "Epoch 71/1000\n",
            "220/220 [==============================] - 97s 442ms/step - loss: 0.1458 - acc: 0.9480 - val_loss: 0.6468 - val_acc: 0.8443\n",
            "Epoch 72/1000\n",
            "220/220 [==============================] - 97s 443ms/step - loss: 0.1489 - acc: 0.9481 - val_loss: 0.6345 - val_acc: 0.8517\n",
            "Epoch 73/1000\n",
            "220/220 [==============================] - 98s 444ms/step - loss: 0.1329 - acc: 0.9530 - val_loss: 0.6049 - val_acc: 0.8523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJgPEycdWwiw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "d11f7606-f7cf-4e5d-9043-c62c84ade60c"
      },
      "source": [
        "!zip -r logs.zip logs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: logs/ (stored 0%)\n",
            "  adding: logs/train/ (stored 0%)\n",
            "  adding: logs/train/events.out.tfevents.1600325235.0cb1e2e845c1.1985.314.v2 (deflated 84%)\n",
            "  adding: logs/train/events.out.tfevents.1600325892.0cb1e2e845c1.1985.14107.v2 (deflated 90%)\n",
            "  adding: logs/train/events.out.tfevents.1600325240.0cb1e2e845c1.profile-empty (deflated 8%)\n",
            "  adding: logs/train/plugins/ (stored 0%)\n",
            "  adding: logs/train/plugins/profile/ (stored 0%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_59_19/ (stored 0%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_59_19/0cb1e2e845c1.overview_page.pb (deflated 60%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_59_19/0cb1e2e845c1.xplane.pb (deflated 81%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_59_19/0cb1e2e845c1.input_pipeline.pb (deflated 57%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_59_19/0cb1e2e845c1.memory_profile.json.gz (stored 0%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_59_19/0cb1e2e845c1.trace.json.gz (deflated 0%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_59_19/0cb1e2e845c1.tensorflow_stats.pb (deflated 75%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_59_19/0cb1e2e845c1.kernel_stats.pb (deflated 93%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_47_20/ (stored 0%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_47_20/0cb1e2e845c1.overview_page.pb (deflated 60%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_47_20/0cb1e2e845c1.xplane.pb (deflated 81%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_47_20/0cb1e2e845c1.input_pipeline.pb (deflated 57%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_47_20/0cb1e2e845c1.memory_profile.json.gz (stored 0%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_47_20/0cb1e2e845c1.trace.json.gz (deflated 0%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_47_20/0cb1e2e845c1.tensorflow_stats.pb (deflated 76%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_47_20/0cb1e2e845c1.kernel_stats.pb (deflated 93%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_58_14/ (stored 0%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_58_14/0cb1e2e845c1.overview_page.pb (deflated 60%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_58_14/0cb1e2e845c1.xplane.pb (deflated 81%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_58_14/0cb1e2e845c1.input_pipeline.pb (deflated 57%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_58_14/0cb1e2e845c1.memory_profile.json.gz (stored 0%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_58_14/0cb1e2e845c1.trace.json.gz (deflated 1%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_58_14/0cb1e2e845c1.tensorflow_stats.pb (deflated 75%)\n",
            "  adding: logs/train/plugins/profile/2020_09_17_06_58_14/0cb1e2e845c1.kernel_stats.pb (deflated 94%)\n",
            "  adding: logs/train/events.out.tfevents.1600325955.0cb1e2e845c1.2152.314.v2 (deflated 87%)\n",
            "  adding: logs/validation/ (stored 0%)\n",
            "  adding: logs/validation/events.out.tfevents.1600325320.0cb1e2e845c1.1985.2842.v2 (deflated 60%)\n",
            "  adding: logs/validation/events.out.tfevents.1600326036.0cb1e2e845c1.2152.2842.v2 (deflated 70%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuCjbtJQXDwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r kaggle.hdf5 '/content/drive/My Drive/'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}